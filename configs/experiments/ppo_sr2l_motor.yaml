defaults:
  - /train/sr2l           # Use SR2L training config
  - /env/realant          # Use RealAnt environment

# Experiment settings
experiment:
  description: "TRUE SR2L - Perturb ACTIONS/MOTORS not observations - Handle motor degradation"
  name: ppo_sr2l_motor
  tags: 
    - ppo
    - sr2l
    - phase3
    - motor-robustness
    - correct-implementation

# Domain randomization disabled (Phase 4)
domain_randomization:
  enabled: false

# TRUE SR2L settings - perturb motor outputs for degradation robustness
sr2l:
  enabled: true
  lambda: 0.001                   # Gentle regularization for motor robustness
  perturbation_std: 0.05          # 5% motor degradation/noise (realistic wear)
  warmup_steps: 1500000           # 1.5M warmup - let it learn clean walking first
  apply_frequency: 2              # Every 2 steps
  use_huber_loss: true            # Robust loss for outliers
  max_perturbation: 0.1           # Max 10% motor degradation (realistic limit)

# Environment settings - Use target walking for fast walking
env:
  name: RealAntMujoco-v0
  use_target_walking: true       # Use target walking for fast movement
  target_distance: 5.0            # Same as the successful model
  
# 15M steps for thorough training
total_timesteps: 15000000        

# Initialize from the successful target walking model
pretrained_model: experiments/ppo_target_walking_llsm451b/best_model/best_model.zip

# Enable W&B logging
logging:
  wandb: true
  wandb_project: "robust-quadruped-rl"
  wandb_entity: "anandpatel1221178-university-of-the-witswatersrand"
  verbose: 1

# Save frequently to track progress
save_freq: 100000
eval_freq: 25000