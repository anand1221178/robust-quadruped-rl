defaults:
  - /train/sr2l           # Use SR2L training config
  - /env/realant          # Use RealAnt environment

# Experiment settings
experiment:
  description: "CORRECTED Gentle SR2L - Observation perturbations for sensor noise robustness"
  name: ppo_sr2l_gentle
  tags: 
    - ppo
    - sr2l
    - phase3
    - sensor-noise-robustness
    - gentle
    - initialized
    - correct-implementation

# Domain randomization disabled (Phase 4)
domain_randomization:
  enabled: false

# GENTLE SR2L settings for sensor noise robustness (per research proposal)
sr2l:
  enabled: true
  lambda: 0.001                   # Gentle regularization for sensor noise
  perturbation_std: 0.01          # Realistic sensor noise levels
  warmup_steps: 2000000           # 2M step warmup - preserve walking first
  apply_frequency: 4              # Less frequent application
  use_huber_loss: true            # Robust loss for outliers
  max_perturbation: 0.03          # Reasonable sensor noise limit

# Environment settings - Use target walking (valid locomotion training)
env:
  name: RealAntMujoco-v0
  use_target_walking: true       # Goal-directed navigation
  target_distance: 5.0           # Same as successful baseline
  
# 15M steps for thorough training
total_timesteps: 15000000        

# Initialize from successful target walking baseline
pretrained_model: experiments/ppo_target_walking_llsm451b/best_model/best_model.zip

# Enable W&B logging
logging:
  wandb: true
  wandb_project: "robust-quadruped-rl"
  wandb_entity: "anandpatel1221178-university-of-the-witswatersrand"
  verbose: 1

# Save frequently to track progress
save_freq: 100000
eval_freq: 25000